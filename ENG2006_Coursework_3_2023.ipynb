{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd65b116",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35fc166edc72a2e7af27007fcf40aeb0",
     "grade": false,
     "grade_id": "cell-bf7989fe63afeb86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ENG2006 Coursework 3\n",
    "\n",
    "## Instructions\n",
    "\n",
    "This assignment carries 50\\% of the module mark. Completed work should be submitted via eBART by **12 noon on Thursday 06/04/2023**.\n",
    "\n",
    "#### Asnswering the questions\n",
    "\n",
    "When answering the questions please keep the following in mind:\n",
    "\n",
    "+ Your submission should consist of the **present notebook and the `imageModelMLPOpt` and `imageModelCNN` folders created in Question 2 only**, any other files will not be taken into consideration.\n",
    "+ Each question should be answered in the cell directly after its description. **New cells should not be added to the notebook**.\n",
    "+ Your questions should consist exclusively of code with comments where necessary.\n",
    "+ **You should not use any `input` commands**.\n",
    "+ Whenever requested, **you should use the variable names specified in the description**.\n",
    "\n",
    "#### Testing your answers\n",
    "\n",
    "This notebook contains some automated tests, which you can run to test your answers before submission. To do this:\n",
    "\n",
    "+ Once you have completed each question and executed the corresponding cell, execute the cell directly after it:\n",
    "    - If your answer passes the tests, a message will appear.\n",
    "    - If not, an error will be trigered. At the very end of the error message, there will be a possible explanation for why the test failed.\n",
    "+ Once you have completed all questions, select the option Restart & Run All from the Kernel menu to ensure that all tests can still be pased.\n",
    "\n",
    "If your answers can pass all the tests and your results seem reasonable, your notebook should be ready for submission. However you should keep in mind that:\n",
    "\n",
    "+ The tests mainly check that the correct variables are created, and only to a limited extent the validity of the results.\n",
    "+ Passing the tests does not guarantee the correctness of your solution.\n",
    "+ Additional tests will be performed after submission.\n",
    "+ As a result, passing the tests for a specific task does not guarantee that you will be awarded all of the corresponding marks.\n",
    "\n",
    "#### Submitting your coursework\n",
    "\n",
    "As mentioned above, your coursework should consist of the present notebook and the `imageModelMLPOpt` and `imageModelCNN` folders to be created in Question 2 only. Once you have answered all of the questions and tested your answers, save the notebook and add it to a .zip file. **Do not include** the `casting_data` folder provided with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e5f00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53676614d02cb29572c3325308da0a05",
     "grade": false,
     "grade_id": "cell-0f8114262731cfbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1 [40 marks]\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"points.png\" width=\"700\" align=\"center\">\n",
    "</div>\n",
    "\n",
    "The provided `points.txt` and `labels.txt` files contain coordinates and labels for a set of points in the 2D plane, divided in classes as shown above. Follow the steps below to train a neural network to classify these points:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e6194e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fdbb1686aa7fa36110ca0c6905165d8",
     "grade": false,
     "grade_id": "cell-49d2f0d605eee480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1-a [3 marks]\n",
    "\n",
    "Read the points and labels and plot them with different colors for each class. Store the points in a numpy array named `points` and the labels in an array named `pointLabels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19292e49",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc6a778227775f46a1b43e80ce83e36b",
     "grade": false,
     "grade_id": "cell-45b3261ab9fd8ac2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "import numpy as np #import numpy module\n",
    "\n",
    "#Import point data\n",
    "data_points = np.loadtxt(\"points.txt\")\n",
    "points = np.array(data_points)\n",
    "\n",
    "#Import label data\n",
    "data_pointLabels = np.loadtxt(\"labels.txt\")\n",
    "pointLabels = np.array(data_pointLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399d2b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "293943285ae16f094a5ad210ca33f297",
     "grade": true,
     "grade_id": "cell-87e9095bc8d41874",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 1-a\n",
    "from tests import question1a\n",
    "question1a(points,pointLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f5f26",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "734356ce58d32f00df54dc4244e3a96e",
     "grade": false,
     "grade_id": "cell-411797e36eefcda6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1-b [2 marks]\n",
    "\n",
    "Divide the data set into three parts by performing:\n",
    "\n",
    "+ A 50-50 split of the original data resulting in a test set consisting of 50% of the original points. Store the points and labels for the test set in variables named `pointsTest` and `pointLabelsTest` respectively.\n",
    "+ A 70-30 split of the remaining data resulting in:\n",
    "    + A training set consisting of 35% of the original data. Store the points and labels for the training set in variables named `pointsTrain` and `pointLabelsTrain` respectively.\n",
    "    + A validation set consisting of 15% of the original data. Store the points and labels for the validation set in variables named `pointsVal` and `pointLabelsVal` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6ec32",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5b38107c59daf8e1dd2b6a0846d2a48",
     "grade": false,
     "grade_id": "cell-bcadc4f877b034df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "from sklearn.model_selection import train_test_split #import split module\n",
    "\n",
    "#Splitting data into corresponding labels\n",
    "points50, pointsTest, pointLabels50, pointLabelsTest = train_test_split(points, pointLabels, test_size=0.5, random_state=42)\n",
    "\n",
    "#Splitting data into corresponding labels\n",
    "pointsTrain, pointsVal, pointLabelsTrain, pointLabelsVal = train_test_split(points50, pointLabels50, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba157de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa09498729e652b8e7470b1103842c35",
     "grade": true,
     "grade_id": "cell-b96a7c15b3098eeb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 1-b\n",
    "from tests import question1b\n",
    "question1b(pointsTrain,pointsVal,pointsTest,pointLabelsTrain,pointLabelsVal,pointLabelsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85890545",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee715d55b9ea41e4e8b8f3603a06cff7",
     "grade": false,
     "grade_id": "cell-0e006b62d5fad238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1-c [30 marks]\n",
    "\n",
    "Using tensorflow, train a feedforward neural network to classify the points using hyperparemeter tuning and early stopping. More specifically, your training code should:\n",
    "\n",
    "+ Consider networks with 1 and 2 hidden layers with ReLU activation.\n",
    "+ Consider networks with 64, 128 and 256 hidden units in each layer.\n",
    "+ Train using the Adam optimiser with categorical sparse cross entropy and stop if the loss for the validation set does not improve for more than 10 consecutive iterations.\n",
    "+ Save the network that achieves the best performance, along with the corresponding loss and accuracy for the validation set, number of hidden layers and number of hidden units.\n",
    "\n",
    "The final model created by the above process should be named `modelOpt`. Similarly, the corresponding loss and accuracy for the validation set, number of hidden layers and number of hidden units should be named `lossOpt`, `accOpt`, `layersOpt` and `unitsOpt` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05ce99",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5ddbe1321eca7ba94ec01e5277ebd91",
     "grade": false,
     "grade_id": "cell-dbf78f34690e04c1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "import tensorflow as tf\n",
    "\n",
    "# Defining hidden units and hidden layers\n",
    "hiddenUnits = [64, 128, 256]\n",
    "hiddenLayers = [1, 2]\n",
    "\n",
    "# Defining test parametersï¼Œabout model, loss, accuracy, layers, and units\n",
    "modelOpt, lossOpt, accOpt, layersOpt, unitsOpt = None, None, None, None, None\n",
    "\n",
    "# Training\n",
    "for num_layers in hiddenLayers:\n",
    "    for num_units in hiddenUnits:\n",
    "        \n",
    "        # Create a model\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        # Add hidden layers\n",
    "        for _ in range(num_layers):\n",
    "            model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
    "\n",
    "        # Add final dense layer with softmax activation\n",
    "        model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='accuracy')\n",
    "\n",
    "        # Early stopping callback\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(pointsTrain, pointLabelsTrain, validation_data=(pointsVal, pointLabelsVal), epochs=1000, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Evaluate the model for the validation set\n",
    "        lossVal, accVal = model.evaluate(pointsVal, pointLabelsVal, verbose=0)\n",
    "\n",
    "        # Save the best model, loss, accuracy, layers, and units\n",
    "        if modelOpt is None or accVal > accOpt:\n",
    "            modelOpt = model\n",
    "            lossOpt = lossVal\n",
    "            accOpt = accVal\n",
    "            layersOpt = num_layers\n",
    "            unitsOpt = num_units\n",
    "\n",
    "# Print details of the optimal model\n",
    "print('Best loss over test set:', lossOpt)\n",
    "print('Best accuracy over test set:', accOpt)\n",
    "print('Number of hidden layers selected:', layersOpt)\n",
    "print('Number of units selected:', unitsOpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6346dc8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f181d4578a51230f14ead1aed9e91af6",
     "grade": true,
     "grade_id": "cell-ac52e32468c65ddf",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 1-c\n",
    "from tests import question1c\n",
    "\n",
    "question1c(layersOpt,unitsOpt,lossOpt,accOpt,modelOpt,pointsVal,pointLabelsVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4050e81d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bed057bde0e45da273dbb73208e3a76",
     "grade": false,
     "grade_id": "cell-ab728fd1b4490abe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1-d [3 marks]\n",
    "\n",
    "Evaluate the accuracy and loss of the trained model for the test set and store them in variables named `accTest` and `lossTest` respectively. Then, create and plot the confusion matrix for the test set. Store the matrix as well as the corresponding display object in variables named `pointsConfusionMatrix` and `pointsConfusionMatrixPlot` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217e683",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4895a8e93404aa973ad5b8f35f222849",
     "grade": false,
     "grade_id": "cell-29f378e55c025fc8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "#import modules\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Use the model to predict the labels of the test data as probabilities and convert to integers\n",
    "labelsPred = modelOpt.predict(pointsTest)\n",
    "labelsPred = np.argmax(labelsPred, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "pointsConfusionMatrix = confusion_matrix(pointLabelsTest, labelsPred)\n",
    "\n",
    "# Create and show confusion matrix plot\n",
    "pointsConfusionMatrixPlot = ConfusionMatrixDisplay(confusion_matrix=pointsConfusionMatrix)\n",
    "pointsConfusionMatrixPlot.plot()\n",
    "\n",
    "# Evaluate the model for the test set\n",
    "lossTest, accTest = modelOpt.evaluate(pointsTest, pointLabelsTest, verbose=0)\n",
    "\n",
    "# Print accuracy and loss\n",
    "print('Test loss:', lossTest)\n",
    "print('Test accuracy:', accTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c586cf1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "949c6149cbb853872aff4ea33cacbfbd",
     "grade": true,
     "grade_id": "cell-f1eb2cfa497061d8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 1-d\n",
    "from tests import question1d\n",
    "\n",
    "question1d(accTest,accOpt,lossTest,pointsConfusionMatrix,pointsConfusionMatrixPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a37e17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32c8eceae30d1284c0f4b61951df2481",
     "grade": false,
     "grade_id": "cell-42e1db9d21697184",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1-e [2 marks]\n",
    "\n",
    "Using the function provided in lecture 2, create a contour plot of the decision boundary for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23e425",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a1fb6eabaab14caa9ce84f89211ba69",
     "grade": true,
     "grade_id": "cell-4b0b92a2bac8087c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "#import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define plot function\n",
    "def plotDecisionBoundary(model,limx=[-1,1], limy=[-1,1], resolution=200, colormap='RdBu'):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    \n",
    "    #create linspaces with the x and y coordinates of the points to be used for the contour plot\n",
    "    xPoints = np.linspace(limx[0], limx[1], resolution)\n",
    "    yPoints = np.linspace(limy[0], limy[1], resolution)\n",
    "\n",
    "    xx, yy = np.meshgrid(xPoints, yPoints)\n",
    "    \n",
    "    modelPred = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    #Determine if the output is two-dimensional and if the size with the second dimension exceeds 1. \n",
    "    #If so, the output is provided as a probability and converted using the argmax function\n",
    "    if len(modelPred.shape) == 2 and modelPred.shape[1] != 1:\n",
    "        modelPred = np.argmax(modelPred, axis=1)\n",
    "    else:\n",
    "        modelPred = modelPred > 0.5\n",
    "\n",
    "    #reshape the labels to the shape of xx and yy so that they can be used for a contour plot\n",
    "    z = modelPred.reshape(xx.shape)\n",
    "\n",
    "    #plot\n",
    "    ax.contourf(xx, yy, z, cmap=colormap, alpha=0.5)\n",
    "    \n",
    "    # return figure and axis\n",
    "    return fig, ax\n",
    "\n",
    "#Calling the defined function\n",
    "fig, ax = plotDecisionBoundary(modelOpt)\n",
    "\n",
    "#Define three different classes\n",
    "class0 = np.argwhere(pointLabels == 0)\n",
    "class1 = np.argwhere(pointLabels == 1)\n",
    "class2 = np.argwhere(pointLabels == 2)\n",
    "\n",
    "#Draw different classes with different colours\n",
    "ax.plot(points[class0, 0], points[class0, 1], '.r')\n",
    "ax.plot(points[class1, 0], points[class1, 1], '.k')\n",
    "ax.plot(points[class2, 0], points[class2, 1], '.b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94511885",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cb33fba188d079c97fc717d8b251df7",
     "grade": false,
     "grade_id": "cell-32ba631b24c6e7ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2 [60 marks]\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div>\n",
    "<img src=\"components.png\" width=\"600\" align=\"center\">\n",
    "</div>\n",
    "\n",
    "The accompanying `casting_data` folder contains images of defective and pristine cast components downloaded from [kaggle](https://www.kaggle.com/datasets/ravirajsinh45/real-life-industrial-dataset-of-casting-product). Images are provided in a size of 300 x 300 pixels, while the dataset is already split into training and testing parts, stored in the corresponding folders (`train` and `test` respectively). Within each folder, two folders can be found containing images of the defective and pristine components (`def_front` and `ok_front` respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a54ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d91d988039c4d5b96ce09358ed51801",
     "grade": false,
     "grade_id": "cell-3f8a8f9a71f3c3fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2-a [3 marks]\n",
    "\n",
    "Using the function provided in lecture 3, read the files as grayscale images, resize them to 150 x 150 pixels and plot one image from each set. Store the images and the labels in variables named `imagesTrain`, `imageLabelsTrain`,`imagesTest`, `imageLabelsTest` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3db1f2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e2900a3c7458bacbabb4bad1633808a",
     "grade": false,
     "grade_id": "cell-a5bf3e8d7a46fc53",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "#import modules\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#input the data from folder\n",
    "train_def = './ENG2006_Coursework_3_2023_Data/casting_data/train/def_front'\n",
    "train_ok = './ENG2006_Coursework_3_2023_Data/casting_data/train/ok_front'\n",
    "test_def = './ENG2006_Coursework_3_2023_Data/casting_data/test/def_front'\n",
    "test_ok = './ENG2006_Coursework_3_2023_Data/casting_data/test/ok_front'\n",
    "\n",
    "#Define data input function\n",
    "def Data_input(folder, label, size=(150, 150)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img_resized = cv2.resize(img, size)\n",
    "            images.append(img_resized)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "imagesTrainDef, labelsTrainDef = Data_input(train_def, 1)\n",
    "imagesTrainOk, labelsTrainOk = Data_input(train_ok, 0)\n",
    "imagesTestDef, labelsTestDef = Data_input(test_def, 1)\n",
    "imagesTestOk, labelsTestOk = Data_input(test_ok, 0)\n",
    "\n",
    "#Merge Def and OK set\n",
    "imagesTrain = imagesTrainDef + imagesTrainOk\n",
    "imageLabelsTrain = labelsTrainDef + labelsTrainOk\n",
    "imagesTest = imagesTestDef + imagesTestOk\n",
    "imageLabelsTest = labelsTestDef + labelsTestOk\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "imagesTrain = np.array(imagesTrain)\n",
    "imageLabelsTrain = np.array(imageLabelsTrain)\n",
    "imagesTest = np.array(imagesTest)\n",
    "imageLabelsTest = np.array(imageLabelsTest)\n",
    "\n",
    "#Normalize the image data:Can affect the training process\n",
    "imagesTrain = imagesTrain / 255.0\n",
    "imagesTest = imagesTest / 255.0\n",
    "\n",
    "# Plot one image from each set\n",
    "\n",
    "# set the size of the picture\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Output photos\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(imagesTrainDef[0], cmap='gray')\n",
    "plt.title('Train Def')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(imagesTrainOk[0], cmap='gray')\n",
    "plt.title('Train OK')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(imagesTestDef[0], cmap='gray')\n",
    "plt.title('Test Def')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(imagesTestOk[0], cmap='gray')\n",
    "plt.title('Test OK')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab60c21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3afd27f93b3cca8e029f1052136bf7c7",
     "grade": true,
     "grade_id": "cell-cdc70aa52b1761cc",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 2-a\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tests import question2a\n",
    "\n",
    "question2a(imagesTrain,imageLabelsTrain,imagesTest,imageLabelsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28f5ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80adb81a3b00c39261d390d0b5381041",
     "grade": false,
     "grade_id": "cell-a5cb57a8e4f10022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2-b [2 marks]\n",
    "\n",
    "Normalise all the data and further split the training set into training and validation parts (75-25 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637e7e7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "769ee8e44a66ae1d0714f8c2ff84fb7a",
     "grade": false,
     "grade_id": "cell-c411922a8bc20428",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# images_training, imagesVal, imagesLabel_training, imageLabelsVal = train_test_split(imagesTrain, imageLabelsTrain, test_size=0.75, random_state=42)\n",
    "imagesTrain, imagesVal, imageLabelsTrain, imageLabelsVal = train_test_split(imagesTrain, imageLabelsTrain, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c58f4c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3ed4922a51f1ac48ffc83ae72f8e0b3",
     "grade": true,
     "grade_id": "cell-07c0d2ffa831ba1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 2-b\n",
    "from tests import question2b\n",
    "\n",
    "question2b(imagesTest,imageLabelsTest,imagesTrain,imageLabelsTrain,imagesVal,imageLabelsVal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78c36657",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72d9171d4a33a6c7e416b1697d226539",
     "grade": false,
     "grade_id": "cell-928d5619acd5ecaa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2-c [15 marks]\n",
    "\n",
    "Using tensorflow, train a feedforward neural network to classify the images using hyperparemeter tuning and early stopping. More specifically, you should chose an appropriate number of hidden units for the network, while your training code should:\n",
    "\n",
    "+ Consider networks with 2, 4 and 8 hidden layers with ReLU activation.\n",
    "+ Train using the Adam optimiser with categorical sparse cross entropy and stop if the loss for the validation set does not improve for more than 5 consecutive iterations.\n",
    "+ Save the network that achieves the best performance, along with the corresponding loss and accuracy for the validation set, number of hidden layers and number of hidden units.\n",
    "\n",
    "The final model created by the above process should be named `imageModelOpt`.\n",
    "\n",
    "When selecting number of hidden units, you should take into account that an excessive number of hidden units might increase the size of the `imageModelMLPOpt` folder beyond the limit allowed in BART.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11654b2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cbf15a6781a0a4b6b0bb9a7ab009ee2",
     "grade": true,
     "grade_id": "cell-64c58cc86e7caa91",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "imagesTrain = imagesTrain.reshape(-1, 150 * 150)\n",
    "imagesVal = imagesVal.reshape(-1, 150 * 150)\n",
    "imagesTest = imagesTest.reshape(-1, 150 * 150)\n",
    "\n",
    "def create_model(hidden_layers, hidden_units):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(150 * 150,)))\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "hidden_layers_options = [2, 4, 8]\n",
    "hidden_units_options = [16, 32, 64, 128]\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "for hidden_layers in hidden_layers_options:\n",
    "    for hidden_units in hidden_units_options:\n",
    "        model = create_model(hidden_layers, hidden_units)\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(imagesTrain, imageLabelsTrain, validation_data=(imagesVal, imageLabelsVal),\n",
    "                            epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "            best_params = {'hidden_layers': hidden_layers, 'hidden_units': hidden_units}\n",
    "            best_val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Best model parameters: {best_params}\")\n",
    "print(f\"Validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Validation accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "imageModelOpt = best_model\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = imageModelOpt.evaluate(imagesTest, imageLabelsTest)\n",
    "\n",
    "# Update the imageMLPAccTest value\n",
    "imageMLPAccTest = test_accuracy\n",
    "\n",
    "# Check the test loss and accuracy\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "\n",
    "\n",
    "imageModelOpt.save(\"imageModelMLPOpt\")\n",
    "#DO NOT delete the following line, it saves your network once it has been trained so that it can be re-used\n",
    "#imageModelMLPOpt.save('imageModelMLPOpt')\n",
    "\n",
    "\n",
    "# # YOUR CODE HERE\n",
    "# #raise NotImplementedError()\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.layers import Dense, Flatten\n",
    "\n",
    "# # Reshape the input data\n",
    "# imagesTrain = imagesTrain.reshape(imagesTrain.shape[0], 150, 150, 1)\n",
    "# imagesVal = imagesVal.reshape(imagesVal.shape[0], 150, 150, 1)\n",
    "\n",
    "# # Possible number of hidden layers\n",
    "# hidden_layers = [2, 4, 8]\n",
    "\n",
    "# # Possible number of hidden units\n",
    "# hidden_units = [32, 64, 128]\n",
    "\n",
    "# # Early stopping with a patience of 5\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# best_model = None\n",
    "# best_loss = float('inf')\n",
    "# best_acc = 0\n",
    "# best_layers = 0\n",
    "# best_units = 0\n",
    "\n",
    "# for layers in hidden_layers:\n",
    "#     for units in hidden_units:\n",
    "#         model = tf.keras.Sequential()\n",
    "        \n",
    "#         # Input layer\n",
    "#         model.add(Flatten(input_shape=(150, 150, 1)))\n",
    "        \n",
    "#         # Add hidden layers with ReLU activation\n",
    "#         for _ in range(layers):\n",
    "#             model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        \n",
    "#         # Add final dense layer with softmax activation\n",
    "#         model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "        \n",
    "#         # Compile and fit the model for the training set\n",
    "#         model.compile(optimizer='adam',\n",
    "#                       loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#                       metrics='accuracy')\n",
    "        \n",
    "#         model.fit(imagesTrain, \n",
    "#                   imageLabelsTrain,\n",
    "#                   validation_data=(imagesVal, imageLabelsVal),\n",
    "#                   epochs=100,\n",
    "#                   callbacks=[early_stopping],verbose=0)\n",
    "        \n",
    "#         # Evaluate model for the validation set\n",
    "#         lossVal, accVal = model.evaluate(imagesVal, imageLabelsVal)\n",
    "#         print(f\"{layers},{units}\")# test\n",
    "#         # If the current model has a higher accuracy than the best model, update the best model\n",
    "#         if accVal > best_acc:\n",
    "#             best_model = model\n",
    "#             best_loss = lossVal\n",
    "#             best_acc = accVal\n",
    "#             best_layers = layers\n",
    "#             best_units = units\n",
    "\n",
    "# # Print details of the optimal model\n",
    "# print('Best loss over validation set: ', best_loss)\n",
    "# print('Best accuracy over validation set: ', best_acc)\n",
    "# print('Number of hidden layers selected: ', best_layers)\n",
    "# print('Number of hidden units selected: ', best_units)\n",
    "\n",
    "# # Save the optimal model\n",
    "# best_model.save('imageModelMLPOpt')\n",
    "\n",
    "\n",
    "\n",
    "# #DO NOT delete the following lines, they load your previously trained model\n",
    "# import tensorflow as tf\n",
    "# imageModelMLPOpt = tf.keras.models.load_model('imageModelMLPOpt')\n",
    "\n",
    "\n",
    "# imageMLPLossTest, imageMLPAccTest = best_model.evaluate(imagesTest, imageLabelsTest, verbose=0)\n",
    "\n",
    "\n",
    "# #Run this cell to test your answer for Question 2-c\n",
    "# from tests import question2c\n",
    "\n",
    "# question2c(imageModelMLPOpt,imageMLPLossTest,imageMLPAccTest,imagesTest,imageLabelsTest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6c0a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0366b20cf55d24a695055a043b588ff1",
     "grade": false,
     "grade_id": "cell-a4779be76a934972",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once your model has successfully trained, evaluate its accuracy and loss for the test set in the following cell and save them in variables named `imageMLPLossTest` and `imageMLPAccTest` respectively. Again, do not delete the first three lines of this file since they are necessary for your answer to be properly marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634e683",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1525119af23ca400b8f7c39c77cad27",
     "grade": false,
     "grade_id": "cell-bfabc5a91035d21f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#DO NOT delete the following lines, they load your previously trained model\n",
    "import tensorflow as tf\n",
    "imageModelMLPOpt = tf.keras.models.load_model('imageModelMLPOpt')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4478478",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95f4127e7fdef2eb52ee1e2c1f9ca3c4",
     "grade": true,
     "grade_id": "cell-d04a43d4f4f7a86d",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 2-c\n",
    "from tests import question2c\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = imageModelOpt.evaluate(imagesTest, imageLabelsTest)\n",
    "\n",
    "# Update the imageMLPAccTest value\n",
    "imageMLPAccTest = test_accuracy\n",
    "imageMLPLossTest = best_val_loss\n",
    "# Check the test loss and accuracy\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "question2c(imageModelMLPOpt,imageMLPLossTest,imageMLPAccTest,imagesTest,imageLabelsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c91bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b0fc2abedcc4f20cc97abab1a0b74d4",
     "grade": false,
     "grade_id": "cell-5187520df3b85a6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Quesion 2-d [20 marks]\n",
    "\n",
    "Using tensorflow, train a convolutional neural network to classify the images. The network should:\n",
    "\n",
    "- Include two convolutional layers with no more than 128 filters, each followed by a max pooling layer.\n",
    "- Include a number of dense layers and hidden units of your choice.\n",
    "- Employ early stopping.\n",
    "- Train within less than 10-15 minutes. Since the exact timing might change in different computers, this requirement is not strict.\n",
    "- Achieve at least 95% accuracy for the test set. The loss and accuracy obtained for the test set should be stored in variables named `imageCNNAccTest` and `imageCNNLossTest`.\n",
    "\n",
    "Determining the exact architecture of the network might require some experimentation. Your submission should only include the final architecture chosen, stored in a model named `imageModelCNN`.\n",
    "\n",
    "Add your training code in the next cell, without deleting the last line. The last line will save your model such that it can be reused without having to repeat training. The model will be saved in a folder named `imageModelCNN`, which has to be submitted along with the notebook. **Full marks cannot be awarded if this file is missing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f3ff7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "367c67bc9fab02363aa300c0745e12cb",
     "grade": true,
     "grade_id": "cell-ca5531afedeb387a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "imagesTrain = imagesTrain.reshape(-1, 150, 150, 1)\n",
    "imagesVal = imagesVal.reshape(-1, 150, 150, 1)\n",
    "imagesTest = imagesTest.reshape(-1, 150, 150, 1)\n",
    "\n",
    "imageModelCNN = create_cnn_model()\n",
    "imageModelCNN.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      metrics='accuracy')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "imageModelCNN.fit(imagesTrain, imageLabelsTrain, validation_data=(imagesVal, imageLabelsVal),\n",
    "                  epochs=100, batch_size=32, callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "imageCNNLossTest, imageCNNAccTest = imageModelCNN.evaluate(imagesTest, imageLabelsTest, verbose=2)\n",
    "print(\"Test loss:\", imageCNNLossTest)\n",
    "print(\"Test accuracy:\", imageCNNAccTest)\n",
    "\n",
    "imageModelCNN.save(\"imageModelCNN\")\n",
    "\n",
    "\n",
    "#DO NOT delete the following line, it saves your network once it has been trained so that it can be re-used\n",
    "imageModelCNN.save('imageModelCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c371447",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b8c5f2e79e1c8f96a3307ddef65baa4",
     "grade": false,
     "grade_id": "cell-7ba061d4ff73c3f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once your model has successfully trained, evaluate its accuracy and loss for the test set in the following cell. Again, do not delete the first three lines of this file since they are necessary for your answer to be properly marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0f84e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "286cf8e27316dd28d3bdf6a16684a1af",
     "grade": false,
     "grade_id": "cell-d911e82c60f0f0a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#DO NOT delete the following lines, they load your previously trained model\n",
    "import tensorflow as tf\n",
    "imageModelCNN = tf.keras.models.load_model('imageModelCNN')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e2b0b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a964e028a9aa58706dde692d6ce7346b",
     "grade": true,
     "grade_id": "cell-41099eebc0bf64c6",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Run this cell to test your answer for Question 2-d\n",
    "from tests import question2d\n",
    "\n",
    "question2d(imageModelCNN,imageCNNLossTest,imageCNNAccTest,imagesTest,imageLabelsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e447b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4067d6f409b50de693b2bc8b33858e83",
     "grade": false,
     "grade_id": "cell-05072ae88f0bc08a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2-e [15 marks]\n",
    "\n",
    "- **A.** Justify your choices for the number of hidden units in **Question 2-c** and the architecture of the neural network of **Question 2-d**.\n",
    "- **B.** Comment on the comparison between the two alternatives (the feedforward neural network of **Question 2-c** and the convolutional neural network of **Question 2-d**), and with justification propose the most suitable one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09789ab9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa393091ec348a8bd67e74b7a56660ae",
     "grade": true,
     "grade_id": "cell-c836f50215efc89d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ae015",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e8ecbb33e8585f37cb212a468963a21",
     "grade": false,
     "grade_id": "cell-d17443b9105abd6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2-f [5marks]\n",
    "\n",
    "For the first 4 images of the test set, visualise the output of the first 2 filters of each of the convolutional layers of the network of **Question 2-d**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6acebe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5a64cd681fc45ec5c51cc256952a371",
     "grade": true,
     "grade_id": "cell-d7f84f8f7a6b6d62",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first two convolutional layers of the CNN model\n",
    "conv_layers = [layer for layer in imageModelCNN.layers if isinstance(layer, tf.keras.layers.Conv2D)][:2]\n",
    "\n",
    "# Create a new model that returns the activations for the convolutional layers\n",
    "activation_model = tf.keras.models.Model(inputs=imageModelCNN.input, outputs=[layer.output for layer in conv_layers])\n",
    "\n",
    "# Obtain the first 4 images from the test set\n",
    "first_4_images = imagesTest[:4]\n",
    "\n",
    "# Get the activations for the first 4 images\n",
    "activations = activation_model.predict(first_4_images)\n",
    "\n",
    "# Plot the original images and the activations for each filter\n",
    "n_images = 4\n",
    "n_filters = 3\n",
    "\n",
    "for i in range(n_images):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.subplot(1, n_filters * 2 + 1, 1)\n",
    "    plt.imshow(first_4_images[i], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(f\"Image {i + 1}\")\n",
    "    \n",
    "    # Plot the activations for each filter\n",
    "    for j in range(len(conv_layers)):\n",
    "        for k in range(n_filters):\n",
    "            plt.subplot(1, n_filters * 2 + 1, j * n_filters + k + 2)\n",
    "            plt.imshow(activations[j][i, :, :, k], cmap='viridis')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(f\"Layer {j + 1} - Filter {k + 1}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the outputs of the first two convolutional layers\n",
    "layerOutputs = [layer.output for layer in imageModelCNN.layers[:2]]\n",
    "\n",
    "# Create a new model that takes the input of the original model and returns the outputs of the first two convolutional layers\n",
    "activationModel = tf.keras.models.Model(inputs=imageModelCNN.input, outputs=layerOutputs)\n",
    "\n",
    "# Get the activations of the first two convolutional layers for the first four images of the test set\n",
    "images = imagesTest[:4]\n",
    "activations = activationModel.predict(images)\n",
    "\n",
    "n_images = 4\n",
    "n_filters = 2\n",
    "plt.figure(figsize=(n_filters * 3, n_images * 3))\n",
    "\n",
    "for i in range(n_images):\n",
    "    for j in range(n_filters):\n",
    "        plt.subplot(n_images, n_filters + 1, i * (n_filters + 1) + j + 1)\n",
    "        plt.imshow(activations[j][i, :, :, 0], cmap='viridis')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Image {i + 1} - Layer {j + 1} - Filter 1\")\n",
    "\n",
    "        plt.subplot(n_images, n_filters + 1, i * (n_filters + 1) + j + 2)\n",
    "        plt.imshow(activations[j][i, :, :, 1], cmap='viridis')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"Image {i + 1} - Layer {j + 1} - Filter 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
